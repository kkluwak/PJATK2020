{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import dstack\n",
    "from pandas import read_csv\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import ConvLSTM2D\n",
    "from keras.utils import to_categorical\n",
    "from matplotlib import pyplot\n",
    "\n",
    "import numpy as np\n",
    "import h5py\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File('Z:\\gait_database\\LSTM_data_onlyMarkersEMG.h5', 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['x_test', 'x_train', 'x_valid', 'y_test', 'y_train', 'y_valid']\n"
     ]
    }
   ],
   "source": [
    "print(list(f.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = f['x_test'][:,:,-16:]\n",
    "x_train = f['x_train'][:,:,-16:]\n",
    "x_valid = f['x_valid'][:,:,-16:]\n",
    "y_test = f['y_test']\n",
    "y_train = f['y_train']\n",
    "y_valid = f['y_valid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "print x_train = (301, 425, 16) y_train = (301, 1)\n",
      "print x_test =  (100, 425, 16) y_test  = (100, 1)\n",
      "print x_valid = (100, 425, 16) y_valid = (100, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"print x_train =\",x_train.shape, \"y_train =\",y_train.shape)\n",
    "print(\"print x_test = \", x_test.shape,\"y_test  =\", y_test.shape)\n",
    "print(\"print x_valid =\",x_valid.shape, \"y_valid =\",y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_group(filenames):\n",
    "    loaded = list()\n",
    "    for name in filenames:\n",
    "        data = f\n",
    "        loaded.append(data)\n",
    "    # grupę stosów, tak aby funkcje były trzecim wymiarem\n",
    "    loaded = dstack(loaded)\n",
    "    return loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "    c = list(zip(x_train,y_train ))\n",
    "    np.random.shuffle(c)\n",
    "    d = list(zip(x_test,y_test ))\n",
    "    np.random.shuffle(d)\n",
    "    v = list(zip(c,d))\n",
    "    np.random.shuffle(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    \n",
    "    c = list(zip(x_train,y_train ))\n",
    "    np.random.shuffle(c)\n",
    "    d = list(zip(x_test,y_test ))\n",
    "    np.random.shuffle(d)\n",
    "    v = list(zip(c,d))\n",
    "    np.random.shuffle(v)\n",
    "    \n",
    "    TrainX = x_train\n",
    "    TestX = x_test\n",
    "    TrainY = y_train\n",
    "    TestY = y_test\n",
    "\n",
    "    TrainY = to_categorical(TrainY)\n",
    "    TestY = to_categorical(TestY)\n",
    "    #print(trenujX.shape, trenujY.shape, testX.shape, testY.shape)\n",
    "    return TrainX, TrainY, TestX, TestY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[0.47765241, 0.38833949, 0.34111948, ..., 0.47068121,\n",
       "          0.38283664, 0.3724125 ],\n",
       "         [0.49767748, 0.39024425, 0.34914225, ..., 0.47443327,\n",
       "          0.39793688, 0.38560514],\n",
       "         [0.51771804, 0.39211173, 0.35709895, ..., 0.47809369,\n",
       "          0.41272024, 0.39835801],\n",
       "         ...,\n",
       "         [0.58218069, 0.40065017, 0.39555756, ..., 0.48562331,\n",
       "          0.41481817, 0.4630288 ],\n",
       "         [0.58203488, 0.40064472, 0.39549365, ..., 0.48563665,\n",
       "          0.41486074, 0.46317013],\n",
       "         [0.5819889 , 0.40064312, 0.39547435, ..., 0.48564089,\n",
       "          0.41487389, 0.46321681]],\n",
       " \n",
       "        [[0.45392692, 0.38764917, 0.32675023, ..., 0.45113569,\n",
       "          0.34808606, 0.38149922],\n",
       "         [0.48644956, 0.39047375, 0.34743345, ..., 0.45359287,\n",
       "          0.35720003, 0.38618735],\n",
       "         [0.51752601, 0.39328   , 0.36701407, ..., 0.45542163,\n",
       "          0.36595456, 0.39056048],\n",
       "         ...,\n",
       "         [0.549724  , 0.40928659, 0.48767483, ..., 0.552489  ,\n",
       "          0.39007488, 0.50152235],\n",
       "         [0.54965344, 0.40928501, 0.48770013, ..., 0.55247536,\n",
       "          0.39006988, 0.50143626],\n",
       "         [0.54962744, 0.40928441, 0.48770845, ..., 0.55247053,\n",
       "          0.39006788, 0.50140442]],\n",
       " \n",
       "        [[0.4127258 , 0.39358298, 0.35061067, ..., 0.46561199,\n",
       "          0.409693  , 0.36003806],\n",
       "         [0.46695364, 0.39512423, 0.36817666, ..., 0.47187295,\n",
       "          0.41481357, 0.37112106],\n",
       "         [0.51986871, 0.39671505, 0.38463664, ..., 0.47801479,\n",
       "          0.41998892, 0.38163777],\n",
       "         ...,\n",
       "         [0.61524876, 0.4125531 , 0.48762378, ..., 0.49446816,\n",
       "          0.40380074, 0.47812046],\n",
       "         [0.61529927, 0.41255305, 0.48766096, ..., 0.4944691 ,\n",
       "          0.40381801, 0.47811211],\n",
       "         [0.61531457, 0.41255274, 0.4876716 , ..., 0.49446932,\n",
       "          0.40382356, 0.47810801]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.40549267, 0.39701858, 0.33193062, ..., 0.47931029,\n",
       "          0.36252128, 0.36135432],\n",
       "         [0.41271238, 0.39869255, 0.33514763, ..., 0.48854738,\n",
       "          0.36518146, 0.36747869],\n",
       "         [0.42004935, 0.40040384, 0.33838222, ..., 0.49751968,\n",
       "          0.36783583, 0.37351912],\n",
       "         ...,\n",
       "         [0.52945762, 0.41975391, 0.36979067, ..., 0.526681  ,\n",
       "          0.47606699, 0.3811367 ],\n",
       "         [0.52944719, 0.41975308, 0.36978522, ..., 0.52669544,\n",
       "          0.47605172, 0.38115183],\n",
       "         [0.52944304, 0.41975268, 0.36978281, ..., 0.5267017 ,\n",
       "          0.47604515, 0.38115865]],\n",
       " \n",
       "        [[0.34470663, 0.39839355, 0.32350642, ..., 0.51190353,\n",
       "          0.33271064, 0.35787477],\n",
       "         [0.36210913, 0.3992393 , 0.32482646, ..., 0.51756681,\n",
       "          0.38624946, 0.36272928],\n",
       "         [0.38020295, 0.40010898, 0.32614357, ..., 0.52333532,\n",
       "          0.43751058, 0.36748798],\n",
       "         ...,\n",
       "         [0.99997208, 0.42715334, 0.34519148, ..., 0.49884372,\n",
       "          0.41207644, 0.48646199],\n",
       "         [0.99996053, 0.42716017, 0.34518899, ..., 0.49884267,\n",
       "          0.41207226, 0.48638413],\n",
       "         [0.9999535 , 0.42716331, 0.34518786, ..., 0.49884224,\n",
       "          0.41207014, 0.48634852]],\n",
       " \n",
       "        [[0.44838121, 0.40165107, 0.32178317, ..., 0.5279255 ,\n",
       "          0.32705953, 0.35555702],\n",
       "         [0.45899864, 0.4036674 , 0.32402973, ..., 0.53825979,\n",
       "          0.39421106, 0.36079305],\n",
       "         [0.46960867, 0.40560244, 0.32629024, ..., 0.54912061,\n",
       "          0.45907472, 0.3659847 ],\n",
       "         ...,\n",
       "         [0.50514384, 0.40963538, 0.33619215, ..., 0.70576549,\n",
       "          0.67505748, 0.37582783],\n",
       "         [0.50515619, 0.4096263 , 0.33619087, ..., 0.70562162,\n",
       "          0.67510215, 0.37581945],\n",
       "         [0.5051604 , 0.40962293, 0.33619032, ..., 0.70556893,\n",
       "          0.67511928, 0.37581634]]]),\n",
       " array([[1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.]], dtype=float32),\n",
       " array([[[0.41677919, 0.3914652 , 0.32611761, ..., 0.46823545,\n",
       "          0.3713795 , 0.36190218],\n",
       "         [0.4268026 , 0.39815228, 0.33113737, ..., 0.47184593,\n",
       "          0.3738625 , 0.36527423],\n",
       "         [0.43654143, 0.40470406, 0.33620991, ..., 0.47546308,\n",
       "          0.37625281, 0.36855385],\n",
       "         ...,\n",
       "         [0.48628784, 0.49913438, 0.34652345, ..., 0.48814662,\n",
       "          0.43592843, 0.50886164],\n",
       "         [0.48622369, 0.49913267, 0.34655489, ..., 0.48814771,\n",
       "          0.43594251, 0.50892059],\n",
       "         [0.48620156, 0.49913181, 0.34656568, ..., 0.48814801,\n",
       "          0.43594733, 0.50893949]],\n",
       " \n",
       "        [[0.41870286, 0.42102894, 0.32097384, ..., 0.47170605,\n",
       "          0.35648205, 0.36614669],\n",
       "         [0.42336191, 0.42734342, 0.3282569 , ..., 0.47462598,\n",
       "          0.36324763, 0.372154  ],\n",
       "         [0.42789754, 0.43340717, 0.33522621, ..., 0.47751824,\n",
       "          0.3698887 , 0.37846417],\n",
       "         ...,\n",
       "         [0.46192458, 0.52068361, 0.39283219, ..., 0.52438921,\n",
       "          0.41524332, 0.37811664],\n",
       "         [0.4619331 , 0.5206814 , 0.39282583, ..., 0.52435278,\n",
       "          0.41522647, 0.37811923],\n",
       "         [0.46193639, 0.52068027, 0.39282321, ..., 0.52433861,\n",
       "          0.41522008, 0.37812053]],\n",
       " \n",
       "        [[0.43514413, 0.40014694, 0.32587731, ..., 0.45251612,\n",
       "          0.38020709, 0.39995452],\n",
       "         [0.43883048, 0.40410756, 0.33651818, ..., 0.45730891,\n",
       "          0.39367602, 0.40658533],\n",
       "         [0.44259152, 0.40805015, 0.34685322, ..., 0.46241615,\n",
       "          0.40670138, 0.41340977],\n",
       "         ...,\n",
       "         [0.45641259, 0.42702671, 0.35834051, ..., 0.4954521 ,\n",
       "          0.37942725, 0.39812433],\n",
       "         [0.45639924, 0.42702553, 0.35834152, ..., 0.49545819,\n",
       "          0.37944518, 0.39811009],\n",
       "         [0.45639482, 0.42702517, 0.35834243, ..., 0.49546036,\n",
       "          0.3794518 , 0.39810522]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.4441092 , 0.42173467, 0.36789829, ..., 0.46675771,\n",
       "          0.31907324, 0.30229436],\n",
       "         [0.46937219, 0.42557992, 0.39288895, ..., 0.4696789 ,\n",
       "          0.35646226, 0.31759596],\n",
       "         [0.49381886, 0.42973341, 0.41671054, ..., 0.47258852,\n",
       "          0.39254508, 0.33221187],\n",
       "         ...,\n",
       "         [0.5902277 , 0.57556387, 0.49502579, ..., 0.50577988,\n",
       "          0.5797301 , 0.38570972],\n",
       "         [0.59021094, 0.57557586, 0.49500936, ..., 0.50578211,\n",
       "          0.57967834, 0.3857075 ],\n",
       "         [0.59020401, 0.57557978, 0.49500253, ..., 0.50578289,\n",
       "          0.57965713, 0.38570667]],\n",
       " \n",
       "        [[0.4012116 , 0.36127589, 0.3924577 , ..., 0.47626378,\n",
       "          0.36208225, 0.32168904],\n",
       "         [0.4291752 , 0.38463941, 0.40385223, ..., 0.47737205,\n",
       "          0.3898295 , 0.33940637],\n",
       "         [0.4564186 , 0.40761472, 0.41482341, ..., 0.47835205,\n",
       "          0.41768176, 0.35594904],\n",
       "         ...,\n",
       "         [0.63857258, 0.60284479, 0.66327868, ..., 0.61056702,\n",
       "          0.54699892, 0.41188873],\n",
       "         [0.6386412 , 0.6028773 , 0.66335016, ..., 0.61065926,\n",
       "          0.54703957, 0.41190043],\n",
       "         [0.63866821, 0.60288941, 0.66337771, ..., 0.61069601,\n",
       "          0.54705605, 0.411905  ]],\n",
       " \n",
       "        [[0.55119187, 0.4966346 , 0.5056688 , ..., 0.44101458,\n",
       "          0.53951677, 0.37277742],\n",
       "         [0.5765379 , 0.51192485, 0.55075951, ..., 0.45014183,\n",
       "          0.55763287, 0.38268753],\n",
       "         [0.6021377 , 0.52712507, 0.59508232, ..., 0.45900105,\n",
       "          0.57526438, 0.39350667],\n",
       "         ...,\n",
       "         [0.8130091 , 0.50192377, 0.56258619, ..., 0.52317074,\n",
       "          0.64882622, 0.40553679],\n",
       "         [0.8129807 , 0.50195863, 0.56267423, ..., 0.52320649,\n",
       "          0.64882285, 0.40554543],\n",
       "         [0.81296769, 0.50197406, 0.56271229, ..., 0.52322233,\n",
       "          0.64882175, 0.40554915]]]),\n",
       " array([[1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.]], dtype=float32))"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(TrainX, TrainY, TestX, TestY):\n",
    "    verbose, epochs, batch_size = 1, 10, 64 # 15, 64 domyslnie, dla 10, 64 działa najlepiej verbose pokaze liczbe epok\n",
    "    \n",
    "    n_timesteps, n_features, n_outputs = TrainX.shape[1], TrainX.shape[2], TrainY.shape[1]\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(100, input_shape=(n_timesteps,n_features)))\n",
    "    model.add(Dropout(0.1)) # 0.5\n",
    "    \n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(n_outputs, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    # fit network\n",
    "    model.fit(TrainX, TrainY, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "    # evaluate model\n",
    "    _, accuracy = model.evaluate(TestX, TestY, batch_size=batch_size, verbose=1)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_results(scores):\n",
    "    print(scores)\n",
    "    m, s = mean(scores), std(scores)\n",
    "    print('Accuracy: %.3f%% (+/-%.3f)' % (m, s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(repeats=10):\n",
    "    # load data\n",
    "    TrainX, TrainY, TestX, TestY = load_dataset()\n",
    "    # repeat experiment\n",
    "    scores = list()\n",
    "    for r in range(repeats):\n",
    "        score = evaluate_model(TrainX, TrainY, TestX, TestY)\n",
    "        score = score * 100.0\n",
    "        print('>#%d: %.3f' % (r+1, score))\n",
    "        scores.append(score)\n",
    "    # summarize results\n",
    "    summarize_results(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5/5 [==============================] - 2s 361ms/step - loss: 0.6870 - accuracy: 0.4950\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 2s 370ms/step - loss: 0.6427 - accuracy: 0.7110\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 2s 374ms/step - loss: 0.5361 - accuracy: 0.8206\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 2s 371ms/step - loss: 0.4463 - accuracy: 0.8140\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 2s 363ms/step - loss: 0.3430 - accuracy: 0.8671\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 2s 380ms/step - loss: 0.2456 - accuracy: 0.9203\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 2s 374ms/step - loss: 0.2194 - accuracy: 0.9236\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 2s 383ms/step - loss: 0.2761 - accuracy: 0.8904\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 2s 374ms/step - loss: 0.2652 - accuracy: 0.9103\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 2s 381ms/step - loss: 0.1717 - accuracy: 0.9468\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001E9367DD280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 1.4834 - accuracy: 0.5200\n",
      ">#1: 52.000\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 2s 344ms/step - loss: 0.6829 - accuracy: 0.5050\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 2s 341ms/step - loss: 0.6495 - accuracy: 0.7209\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 2s 350ms/step - loss: 0.5752 - accuracy: 0.7940\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 2s 351ms/step - loss: 0.4337 - accuracy: 0.8206\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 2s 353ms/step - loss: 0.3101 - accuracy: 0.8870\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 2s 366ms/step - loss: 0.2379 - accuracy: 0.9236\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 2s 351ms/step - loss: 0.1992 - accuracy: 0.9269\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 2s 350ms/step - loss: 0.1661 - accuracy: 0.9435\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 2s 343ms/step - loss: 0.1608 - accuracy: 0.9535\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 2s 353ms/step - loss: 0.0856 - accuracy: 0.9734\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001E9570C95E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 1.4969 - accuracy: 0.5800\n",
      ">#2: 58.000\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 2s 390ms/step - loss: 0.6871 - accuracy: 0.5282\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 2s 373ms/step - loss: 0.6625 - accuracy: 0.6080\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 2s 385ms/step - loss: 0.5920 - accuracy: 0.7708\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 2s 376ms/step - loss: 0.3842 - accuracy: 0.9203\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 2s 388ms/step - loss: 0.2988 - accuracy: 0.8771\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 2s 393ms/step - loss: 0.2317 - accuracy: 0.9336\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 2s 398ms/step - loss: 0.1535 - accuracy: 0.9601\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 2s 388ms/step - loss: 0.1360 - accuracy: 0.9568\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 2s 381ms/step - loss: 0.1457 - accuracy: 0.9601\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 2s 388ms/step - loss: 0.0750 - accuracy: 0.9767\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001E92A895CA0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 1.5892 - accuracy: 0.5500\n",
      ">#3: 55.000\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 2s 386ms/step - loss: 0.6786 - accuracy: 0.5515\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 2s 387ms/step - loss: 0.6348 - accuracy: 0.7243\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 2s 385ms/step - loss: 0.4891 - accuracy: 0.8339\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 2s 374ms/step - loss: 0.3006 - accuracy: 0.8804\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 2s 380ms/step - loss: 0.2503 - accuracy: 0.9136\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 2s 371ms/step - loss: 0.2400 - accuracy: 0.9169\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 2s 388ms/step - loss: 0.1341 - accuracy: 0.9601\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 2s 370ms/step - loss: 0.1533 - accuracy: 0.9601\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 2s 397ms/step - loss: 0.3616 - accuracy: 0.8738\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 2s 374ms/step - loss: 0.3415 - accuracy: 0.8505\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001E925709430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 1.1078 - accuracy: 0.5100\n",
      ">#4: 51.000\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 2s 381ms/step - loss: 0.6942 - accuracy: 0.5282\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 2s 381ms/step - loss: 0.6685 - accuracy: 0.5681\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 2s 382ms/step - loss: 0.6130 - accuracy: 0.7674\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 2s 397ms/step - loss: 0.4824 - accuracy: 0.8206\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 2s 380ms/step - loss: 0.3792 - accuracy: 0.8472\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 2s 379ms/step - loss: 0.3151 - accuracy: 0.9037\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 2s 380ms/step - loss: 0.2215 - accuracy: 0.9402\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 2s 376ms/step - loss: 0.1766 - accuracy: 0.9435\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 385ms/step - loss: 0.1191 - accuracy: 0.9668\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 2s 391ms/step - loss: 0.2189 - accuracy: 0.9236\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001E924450790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 2.0537 - accuracy: 0.5200\n",
      ">#5: 52.000\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 2s 376ms/step - loss: 0.7026 - accuracy: 0.5249\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 2s 379ms/step - loss: 0.6776 - accuracy: 0.5681\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 2s 370ms/step - loss: 0.6344 - accuracy: 0.7608\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 2s 384ms/step - loss: 0.5303 - accuracy: 0.8372\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 2s 379ms/step - loss: 0.4434 - accuracy: 0.8140\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 2s 382ms/step - loss: 0.4210 - accuracy: 0.8605\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 2s 374ms/step - loss: 0.4519 - accuracy: 0.8405\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 2s 389ms/step - loss: 0.3645 - accuracy: 0.8704\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 2s 377ms/step - loss: 0.2263 - accuracy: 0.9468\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 2s 382ms/step - loss: 0.1965 - accuracy: 0.9203\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001E92D1C08B0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6046 - accuracy: 0.7100\n",
      ">#6: 71.000\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 2s 380ms/step - loss: 0.6875 - accuracy: 0.5415\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 2s 370ms/step - loss: 0.6451 - accuracy: 0.7110\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 2s 378ms/step - loss: 0.5491 - accuracy: 0.8106\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 2s 377ms/step - loss: 0.5573 - accuracy: 0.7542\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 2s 372ms/step - loss: 0.8723 - accuracy: 0.5183\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 2s 380ms/step - loss: 0.6832 - accuracy: 0.5316\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 2s 385ms/step - loss: 0.5453 - accuracy: 0.8505\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 2s 380ms/step - loss: 0.5393 - accuracy: 0.5880\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 2s 366ms/step - loss: 0.4109 - accuracy: 0.9003\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 2s 378ms/step - loss: 0.4079 - accuracy: 0.9502\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001E9398B4280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 1.3269 - accuracy: 0.5900\n",
      ">#7: 59.000\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 2s 375ms/step - loss: 0.6889 - accuracy: 0.5316\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 2s 385ms/step - loss: 0.6608 - accuracy: 0.6412\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 2s 374ms/step - loss: 0.6060 - accuracy: 0.8439\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 2s 368ms/step - loss: 0.4522 - accuracy: 0.8937\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 2s 373ms/step - loss: 0.5090 - accuracy: 0.7674\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 2s 370ms/step - loss: 0.4688 - accuracy: 0.7176\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 2s 380ms/step - loss: 0.4185 - accuracy: 0.8837\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 2s 374ms/step - loss: 0.3902 - accuracy: 0.8771\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 2s 390ms/step - loss: 0.2826 - accuracy: 0.9169\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 2s 371ms/step - loss: 0.1347 - accuracy: 0.9468\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001E929819670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 1.7232 - accuracy: 0.6100\n",
      ">#8: 61.000\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 2s 381ms/step - loss: 0.6817 - accuracy: 0.4983\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 2s 379ms/step - loss: 0.6451 - accuracy: 0.6844\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 2s 372ms/step - loss: 0.5904 - accuracy: 0.7010\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 2s 396ms/step - loss: 0.4625 - accuracy: 0.7841\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 2s 383ms/step - loss: 0.3130 - accuracy: 0.8937\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 2s 369ms/step - loss: 0.2413 - accuracy: 0.9070\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 2s 377ms/step - loss: 0.2028 - accuracy: 0.9336\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 2s 371ms/step - loss: 0.1705 - accuracy: 0.9402\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 2s 384ms/step - loss: 0.1312 - accuracy: 0.9535\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 2s 381ms/step - loss: 0.2763 - accuracy: 0.9003\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001E92A45C160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 51ms/step - loss: 0.9193 - accuracy: 0.6000\n",
      ">#9: 60.000\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 2s 379ms/step - loss: 0.6853 - accuracy: 0.5648\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 2s 384ms/step - loss: 0.6435 - accuracy: 0.6312\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 2s 360ms/step - loss: 0.5680 - accuracy: 0.7475\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 2s 387ms/step - loss: 0.4709 - accuracy: 0.7641\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 2s 338ms/step - loss: 0.4080 - accuracy: 0.8239\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 2s 371ms/step - loss: 0.2479 - accuracy: 0.9169\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 2s 390ms/step - loss: 0.1631 - accuracy: 0.9535\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 2s 390ms/step - loss: 0.1098 - accuracy: 0.9801\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 2s 386ms/step - loss: 0.1067 - accuracy: 0.9701\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 2s 377ms/step - loss: 0.1228 - accuracy: 0.9535\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001E92346F700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.7588 - accuracy: 0.5900\n",
      ">#10: 59.000\n",
      "[51.99999809265137, 57.999998331069946, 55.000001192092896, 50.999999046325684, 51.99999809265137, 70.99999785423279, 58.99999737739563, 61.000001430511475, 60.00000238418579, 58.99999737739563]\n",
      "Accuracy: 57.800% (+/-5.600)\n"
     ]
    }
   ],
   "source": [
    "run_experiment(repeats=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
