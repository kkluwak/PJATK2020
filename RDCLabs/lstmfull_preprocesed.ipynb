{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import dstack\n",
    "from pandas import read_csv\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import ConvLSTM2D\n",
    "from keras.utils import to_categorical\n",
    "from matplotlib import pyplot\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File('C:/Users/huboz/Desktop/Pjatk/HARDataset/full_preprocesed.h5', 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['x', 'y_features', 'y_move', 'y_person']\n"
     ]
    }
   ],
   "source": [
    "print(list(f.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x = f['x'][:,:,-16:]\n",
    "y = f['y_move']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2927, 425, 16) (2927, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape,y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_group(filenames):\n",
    "    loaded = list()\n",
    "    for name in filenames:\n",
    "        data = f\n",
    "        loaded.append(data)\n",
    "    # grupę stosów, tak aby funkcje były trzecim wymiarem\n",
    "    loaded = dstack(loaded)\n",
    "    return loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = x[0:2927]\n",
    "Y = y[0:2927]\n",
    "   \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = list(zip(X,Y))\n",
    "np.random.shuffle(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    \n",
    "   \n",
    "    c = list(zip(X,Y))\n",
    "    np.random.shuffle(c)\n",
    "    \n",
    "    TrainX = X[0:2047]\n",
    "    TestX = X[2048:2927]\n",
    "    TrainY = Y[0:2047]\n",
    "    TestY = Y[2048:2927]\n",
    "\n",
    "    TrainY = to_categorical(TrainY)\n",
    "    TestY = to_categorical(TestY)\n",
    "    \n",
    "    return TrainX, TrainY, TestX, TestY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[ 1.30208853e-01, -2.84142152e-03,  3.92287044e-02, ...,\n",
       "           1.95956089e-02,  4.21961549e-02,  3.24824422e-02],\n",
       "         [ 1.63553743e-01,  2.81515983e-04,  5.09274047e-02, ...,\n",
       "           2.65451790e-02,  6.56309042e-02,  5.28208185e-02],\n",
       "         [ 1.96924450e-01,  3.34332876e-03,  6.25297690e-02, ...,\n",
       "           3.33250057e-02,  8.85738783e-02,  7.24812301e-02],\n",
       "         ...,\n",
       "         [ 3.04264934e-01,  1.73424214e-02,  1.18609637e-01, ...,\n",
       "           4.72713753e-02,  9.18297540e-02,  1.72180678e-01],\n",
       "         [ 3.04022134e-01,  1.73334941e-02,  1.18516435e-01, ...,\n",
       "           4.72960850e-02,  9.18958161e-02,  1.72398558e-01],\n",
       "         [ 3.03945564e-01,  1.73308746e-02,  1.18488291e-01, ...,\n",
       "           4.73039420e-02,  9.19162231e-02,  1.72470514e-01]],\n",
       " \n",
       "        [[ 9.07021586e-02, -3.97322117e-03,  1.82756512e-02, ...,\n",
       "          -1.66066097e-02, -1.17348478e-02,  4.64909426e-02],\n",
       "         [ 1.44857488e-01,  6.57794046e-04,  4.84356636e-02, ...,\n",
       "          -1.20554172e-02,  2.40954376e-03,  5.37183763e-02],\n",
       "         [ 1.96604692e-01,  5.25875008e-03,  7.69878744e-02, ...,\n",
       "          -8.66817722e-03,  1.59960895e-02,  6.04602045e-02],\n",
       "         ...,\n",
       "         [ 2.50219425e-01,  3.15021708e-02,  2.52933870e-01, ...,\n",
       "           1.71120022e-01,  5.34295146e-02,  2.31524088e-01],\n",
       "         [ 2.50101929e-01,  3.14995840e-02,  2.52970772e-01, ...,\n",
       "           1.71094748e-01,  5.34217622e-02,  2.31391361e-01],\n",
       "         [ 2.50058625e-01,  3.14986056e-02,  2.52982899e-01, ...,\n",
       "           1.71085813e-01,  5.34186583e-02,  2.31342287e-01]],\n",
       " \n",
       "        [[ 2.20958023e-02,  5.75548674e-03,  5.30686383e-02, ...,\n",
       "           1.02063990e-02,  8.38757633e-02,  1.34054385e-02],\n",
       "         [ 1.12393717e-01,  8.28242992e-03,  7.86831525e-02, ...,\n",
       "           2.18029497e-02,  9.18226149e-02,  3.04914997e-02],\n",
       "         [ 2.00505657e-01,  1.08906520e-02,  1.02684881e-01, ...,\n",
       "           3.31788768e-02,  9.98544722e-02,  4.67045354e-02],\n",
       "         ...,\n",
       "         [ 3.59328488e-01,  3.68577531e-02,  2.52859444e-01, ...,\n",
       "           6.36538147e-02,  7.47313061e-02,  1.95446670e-01],\n",
       "         [ 3.59412589e-01,  3.68576737e-02,  2.52913651e-01, ...,\n",
       "           6.36555400e-02,  7.47580978e-02,  1.95433795e-01],\n",
       "         [ 3.59438060e-01,  3.68571590e-02,  2.52929171e-01, ...,\n",
       "           6.36559490e-02,  7.47667186e-02,  1.95427464e-01]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2.13090998e-01,  5.03825497e-02,  2.02664359e-02, ...,\n",
       "           5.30956853e-02,  5.14921718e-02,  4.07695662e-02],\n",
       "         [ 2.60715184e-01,  7.38040845e-02,  3.96863970e-02, ...,\n",
       "           6.48663176e-02,  7.13041480e-02,  5.19134524e-02],\n",
       "         [ 3.07111860e-01,  9.68202983e-02,  5.86281494e-02, ...,\n",
       "           7.54003051e-02,  8.83761053e-02,  6.29498239e-02],\n",
       "         ...,\n",
       "         [ 6.14161264e-01,  2.40193534e-01,  5.50097971e-01, ...,\n",
       "           3.36939313e-01,  1.48478690e-01,  1.72298691e-01],\n",
       "         [ 6.14118310e-01,  2.40205588e-01,  5.50096941e-01, ...,\n",
       "           3.36814492e-01,  1.48445220e-01,  1.72422459e-01],\n",
       "         [ 6.14101985e-01,  2.40210211e-01,  5.50092384e-01, ...,\n",
       "           3.36770243e-01,  1.48433948e-01,  1.72464960e-01]],\n",
       " \n",
       "        [[ 1.35020590e-01,  9.69745598e-02,  2.17371785e-02, ...,\n",
       "           4.09127623e-02,  3.34939389e-02,  2.00186227e-02],\n",
       "         [ 1.89376074e-01,  1.03630317e-01,  4.19020142e-02, ...,\n",
       "           6.13730482e-02,  4.00377638e-02,  2.20869479e-02],\n",
       "         [ 2.42264356e-01,  1.10332173e-01,  6.18947684e-02, ...,\n",
       "           8.14965687e-02,  4.65123881e-02,  2.41829231e-02],\n",
       "         ...,\n",
       "         [ 7.01902788e-01,  2.29123516e-01,  2.40293983e-01, ...,\n",
       "           2.94548460e-01,  1.38110463e-01,  5.74257382e-02],\n",
       "         [ 7.01866277e-01,  2.29016455e-01,  2.40252157e-01, ...,\n",
       "           2.94546994e-01,  1.38050962e-01,  5.74233696e-02],\n",
       "         [ 7.01853146e-01,  2.28974815e-01,  2.40235648e-01, ...,\n",
       "           2.94547328e-01,  1.38027648e-01,  5.74222165e-02]],\n",
       " \n",
       "        [[ 2.81607541e-01,  1.34080005e-01,  9.97803501e-02, ...,\n",
       "           1.52809373e-01,  8.97568886e-02, -2.46101160e-03],\n",
       "         [ 3.37442593e-01,  1.73922480e-01,  1.13283255e-01, ...,\n",
       "           1.91459195e-01,  1.02995852e-01,  4.10000547e-03],\n",
       "         [ 3.94792162e-01,  2.10451005e-01,  1.26655782e-01, ...,\n",
       "           2.29044636e-01,  1.15516569e-01,  1.04570193e-02],\n",
       "         ...,\n",
       "         [ 3.74972202e-01,  2.17308828e-01,  2.68531879e-01, ...,\n",
       "           5.88142564e-01,  2.96838460e-01,  2.71098700e-02],\n",
       "         [ 3.75026761e-01,  2.17345357e-01,  2.68548650e-01, ...,\n",
       "           5.88247722e-01,  2.96859431e-01,  2.71125748e-02],\n",
       "         [ 3.75045378e-01,  2.17358758e-01,  2.68554800e-01, ...,\n",
       "           5.88285909e-01,  2.96866831e-01,  2.71138192e-02]]]),\n",
       " array([[1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.]], dtype=float32),\n",
       " array([[[ 3.32788639e-02,  2.46418845e-01,  8.27043796e-02, ...,\n",
       "           1.42929222e-01,  2.72091185e-02, -5.07157079e-03],\n",
       "         [ 1.20325116e-01,  2.85857949e-01,  1.00574293e-01, ...,\n",
       "           1.61793882e-01,  3.35981291e-02, -1.68524350e-03],\n",
       "         [ 2.07064593e-01,  3.24145874e-01,  1.18603624e-01, ...,\n",
       "           1.81567778e-01,  4.01829647e-02,  1.74418819e-03],\n",
       "         ...,\n",
       "         [ 9.38257666e-01,  3.19170933e-01,  2.81391406e-01, ...,\n",
       "           4.25562480e-01,  9.80219352e-02,  1.53131385e-02],\n",
       "         [ 9.37972354e-01,  3.19244274e-01,  2.81360587e-01, ...,\n",
       "           4.25466806e-01,  9.79958492e-02,  1.53120167e-02],\n",
       "         [ 9.37858679e-01,  3.19272806e-01,  2.81348033e-01, ...,\n",
       "           4.25428990e-01,  9.79857143e-02,  1.53115972e-02]],\n",
       " \n",
       "        [[ 3.11885783e-03,  4.23508684e-02,  1.26078802e-01, ...,\n",
       "           7.05439777e-02, -2.23140461e-02,  2.98056951e-03],\n",
       "         [ 1.92239291e-02,  6.08070768e-02,  1.45662145e-01, ...,\n",
       "           9.77036451e-02, -2.31917362e-03,  4.05945790e-03],\n",
       "         [ 3.49950183e-02,  7.86324907e-02,  1.64907274e-01, ...,\n",
       "           1.24227467e-01,  1.71874621e-02,  5.16153404e-03],\n",
       "         ...,\n",
       "         [ 5.34323822e-01,  2.30546808e-01,  3.89446138e-01, ...,\n",
       "           2.68577509e-01,  1.35967942e-01,  6.70949000e-02],\n",
       "         [ 5.34328548e-01,  2.30519406e-01,  3.89416740e-01, ...,\n",
       "           2.68579177e-01,  1.35918229e-01,  6.71262788e-02],\n",
       "         [ 5.34327829e-01,  2.30507604e-01,  3.89403575e-01, ...,\n",
       "           2.68578210e-01,  1.35898955e-01,  6.71387707e-02]],\n",
       " \n",
       "        [[ 8.62613935e-03,  4.97640990e-02,  1.76754764e-01, ...,\n",
       "           9.96152544e-02,  7.99541317e-03,  7.60898863e-03],\n",
       "         [ 2.71667189e-02,  5.61453330e-02,  2.16226267e-01, ...,\n",
       "           1.19540167e-01,  1.65511214e-02,  1.04068612e-02],\n",
       "         [ 4.53673352e-02,  6.31435772e-02,  2.55292612e-01, ...,\n",
       "           1.38720740e-01,  2.49584293e-02,  1.32969310e-02],\n",
       "         ...,\n",
       "         [ 4.58799724e-01,  5.15196811e-01,  3.73401771e-01, ...,\n",
       "           4.82376013e-01,  1.35962763e-01,  4.46576970e-02],\n",
       "         [ 4.58567371e-01,  5.15244356e-01,  3.73349588e-01, ...,\n",
       "           4.82249215e-01,  1.35926859e-01,  4.46676083e-02],\n",
       "         [ 4.58481931e-01,  5.15262769e-01,  3.73330274e-01, ...,\n",
       "           4.82202754e-01,  1.35913883e-01,  4.46711669e-02]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2.22369842e-01, -7.65478756e-04,  6.47327847e-02, ...,\n",
       "          -1.97016928e-01, -1.18436203e-01,  3.14554213e-01],\n",
       "         [ 2.34080502e-01,  4.08095870e-03,  7.29086372e-02, ...,\n",
       "          -1.62416074e-01, -8.02940269e-02,  3.51371786e-01],\n",
       "         [ 2.46135137e-01,  8.96387579e-03,  8.14921011e-02, ...,\n",
       "          -1.28221844e-01, -4.24296857e-02,  3.87860903e-01],\n",
       "         ...,\n",
       "         [ 7.04574930e-01,  1.17192143e-01,  2.02168149e-01, ...,\n",
       "           6.10399323e-01,  9.99887557e-01,  7.75100375e-01],\n",
       "         [ 7.04566277e-01,  1.17183145e-01,  2.02152770e-01, ...,\n",
       "           6.10403533e-01,  9.99957346e-01,  7.75110885e-01],\n",
       "         [ 7.04560794e-01,  1.17177669e-01,  2.02143400e-01, ...,\n",
       "           6.10405907e-01,  1.00000000e+00,  7.75116959e-01]],\n",
       " \n",
       "        [[-2.66153334e-02,  1.97520588e-02,  1.34206564e-02, ...,\n",
       "           3.09091499e-01,  2.19717631e-01,  3.26848651e-02],\n",
       "         [ 1.11151258e-02,  2.32039091e-02,  1.94997133e-02, ...,\n",
       "           3.40913974e-01,  2.70739878e-01,  4.67875252e-02],\n",
       "         [ 4.87433071e-02,  2.66500311e-02,  2.56884476e-02, ...,\n",
       "           3.72756261e-01,  3.20574816e-01,  6.09375651e-02],\n",
       "         ...,\n",
       "         [ 6.90552438e-01,  3.08270377e-01,  1.69669344e-01, ...,\n",
       "           5.52868110e-01,  9.99996266e-01,  4.50884680e-01],\n",
       "         [ 6.90570514e-01,  3.08286187e-01,  1.69660422e-01, ...,\n",
       "           5.52861451e-01,  9.99998756e-01,  4.50884201e-01],\n",
       "         [ 6.90581497e-01,  3.08295669e-01,  1.69654982e-01, ...,\n",
       "           5.52857434e-01,  1.00000000e+00,  4.50883830e-01]],\n",
       " \n",
       "        [[-4.44469564e-03, -3.71429012e-02,  4.14589698e-02, ...,\n",
       "          -1.19392138e-01,  2.84064317e-01,  3.45216171e-01],\n",
       "         [ 2.39598295e-02, -2.35481808e-02,  4.50273043e-02, ...,\n",
       "          -6.13979098e-02,  3.13890443e-01,  3.75127260e-01],\n",
       "         [ 5.23120516e-02, -1.00843691e-02,  4.85455854e-02, ...,\n",
       "          -3.91533219e-03,  3.43936810e-01,  4.05196351e-01],\n",
       "         ...,\n",
       "         [ 5.67351952e-01,  2.41618982e-01,  1.82316843e-01, ...,\n",
       "           6.97054615e-01,  9.91858225e-01,  6.93190054e-01],\n",
       "         [ 5.67369374e-01,  2.41612432e-01,  1.82315005e-01, ...,\n",
       "           6.97079915e-01,  9.91843599e-01,  6.93179894e-01],\n",
       "         [ 5.67379297e-01,  2.41608514e-01,  1.82313869e-01, ...,\n",
       "           6.97094417e-01,  9.91834815e-01,  6.93174063e-01]]]),\n",
       " array([[0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1., 0.]], dtype=float32))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(TrainX, TrainY, TestX, TestY):\n",
    "    verbose, epochs, batch_size = 1, 10, 64 # 15, 64 domyslnie, dla 10, 64 działa najlepiej verbose pokaze liczbe epok\n",
    "    \n",
    "    n_timesteps, n_features, n_outputs = TrainX.shape[1], TrainX.shape[2], TrainY.shape[1]\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(100, input_shape=(n_timesteps,n_features)))\n",
    "    model.add(Dropout(0.1)) # 0.5\n",
    "    \n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(n_outputs, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    # fit network\n",
    "    model.fit(TrainX, TrainY, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "    # evaluate model\n",
    "    _, accuracy = model.evaluate(TestX, TestY, batch_size=batch_size, verbose=1)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_results(scores):\n",
    "    print(scores)\n",
    "    m, s = mean(scores), std(scores)\n",
    "    print('Accuracy: %.3f%% (+/-%.3f)' % (m, s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(repeats=10):\n",
    "    # load data\n",
    "    TrainX, TrainY, TestX, TestY = load_dataset()\n",
    "    # repeat experiment\n",
    "    scores = list()\n",
    "    for r in range(repeats):\n",
    "        score = evaluate_model(TrainX, TrainY, TestX, TestY)\n",
    "        score = score * 100.0\n",
    "        print('>#%d: %.3f' % (r+1, score))\n",
    "        scores.append(score)\n",
    "    # summarize results\n",
    "    summarize_results(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "32/32 [==============================] - 9s 296ms/step - loss: 1.4842 - accuracy: 0.3166\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 9s 289ms/step - loss: 1.2491 - accuracy: 0.4436\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 10s 309ms/step - loss: 1.1688 - accuracy: 0.4880\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 11s 350ms/step - loss: 1.1274 - accuracy: 0.4831\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 11s 349ms/step - loss: 1.1675 - accuracy: 0.4841\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 11s 356ms/step - loss: 1.0810 - accuracy: 0.5247\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 12s 367ms/step - loss: 1.0145 - accuracy: 0.5545\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 12s 379ms/step - loss: 0.9719 - accuracy: 0.5901\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 14s 425ms/step - loss: 1.0192 - accuracy: 0.5823\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 25s 780ms/step - loss: 0.9790 - accuracy: 0.5896\n",
      "14/14 [==============================] - 2s 141ms/step - loss: 1.9051 - accuracy: 0.4118\n",
      ">#1: 41.183\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 16s 502ms/step - loss: 1.4445 - accuracy: 0.3566\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 16s 498ms/step - loss: 1.4055 - accuracy: 0.4118\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 15s 464ms/step - loss: 1.2883 - accuracy: 0.4787\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 15s 481ms/step - loss: 1.1811 - accuracy: 0.4993\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 15s 482ms/step - loss: 1.0637 - accuracy: 0.5442\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 14s 453ms/step - loss: 1.0789 - accuracy: 0.5354\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 15s 458ms/step - loss: 1.0682 - accuracy: 0.5467\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 15s 455ms/step - loss: 1.0826 - accuracy: 0.5247\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 15s 458ms/step - loss: 1.0639 - accuracy: 0.5530\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 15s 459ms/step - loss: 0.9836 - accuracy: 0.5877\n",
      "14/14 [==============================] - 1s 89ms/step - loss: 1.5457 - accuracy: 0.4096\n",
      ">#2: 40.956\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 14s 439ms/step - loss: 1.5182 - accuracy: 0.3136\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 14s 448ms/step - loss: 1.3671 - accuracy: 0.4025\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 15s 459ms/step - loss: 1.3362 - accuracy: 0.4094\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 15s 458ms/step - loss: 1.1965 - accuracy: 0.4768\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 14s 452ms/step - loss: 1.1399 - accuracy: 0.4934\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 14s 452ms/step - loss: 1.1564 - accuracy: 0.4900\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 16s 486ms/step - loss: 1.1189 - accuracy: 0.5144\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 16s 485ms/step - loss: 1.0682 - accuracy: 0.5374\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 16s 496ms/step - loss: 1.0171 - accuracy: 0.5598\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 17s 531ms/step - loss: 0.9747 - accuracy: 0.5848\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 1.5293 - accuracy: 0.4175\n",
      ">#3: 41.752\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 16s 488ms/step - loss: 1.4939 - accuracy: 0.2921\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 16s 508ms/step - loss: 1.3420 - accuracy: 0.4079\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 17s 529ms/step - loss: 1.2355 - accuracy: 0.4494\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 17s 524ms/step - loss: 1.1732 - accuracy: 0.4817\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 16s 503ms/step - loss: 1.1636 - accuracy: 0.4719\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 16s 504ms/step - loss: 1.0747 - accuracy: 0.5252\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 15s 481ms/step - loss: 1.0196 - accuracy: 0.5608\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 15s 478ms/step - loss: 1.0566 - accuracy: 0.5281\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 15s 466ms/step - loss: 0.9895 - accuracy: 0.5716\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 15s 470ms/step - loss: 0.9942 - accuracy: 0.5677\n",
      "14/14 [==============================] - 1s 95ms/step - loss: 1.3683 - accuracy: 0.4824\n",
      ">#4: 48.237\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 15s 455ms/step - loss: 1.4405 - accuracy: 0.3439\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 15s 455ms/step - loss: 1.2464 - accuracy: 0.4299\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 14s 451ms/step - loss: 1.2129 - accuracy: 0.4719\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 16s 505ms/step - loss: 1.1272 - accuracy: 0.5159\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 16s 494ms/step - loss: 1.1365 - accuracy: 0.4905\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 16s 515ms/step - loss: 1.0768 - accuracy: 0.5203\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 16s 506ms/step - loss: 1.0868 - accuracy: 0.5354\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 16s 515ms/step - loss: 1.0110 - accuracy: 0.5725\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 16s 508ms/step - loss: 0.9969 - accuracy: 0.5936\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 16s 506ms/step - loss: 0.9947 - accuracy: 0.5755\n",
      "14/14 [==============================] - 1s 99ms/step - loss: 1.7809 - accuracy: 0.3083\n",
      ">#5: 30.830\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 15s 458ms/step - loss: 1.4710 - accuracy: 0.3249\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 16s 512ms/step - loss: 1.2424 - accuracy: 0.4485\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 19s 607ms/step - loss: 1.1968 - accuracy: 0.4690\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 20s 624ms/step - loss: 1.1287 - accuracy: 0.4890\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 20s 638ms/step - loss: 1.0993 - accuracy: 0.5232\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 21s 643ms/step - loss: 1.1364 - accuracy: 0.5305\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 19s 584ms/step - loss: 1.1226 - accuracy: 0.5296\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 16s 515ms/step - loss: 1.0767 - accuracy: 0.5276\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 16s 487ms/step - loss: 1.0445 - accuracy: 0.5496\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 15s 481ms/step - loss: 1.0184 - accuracy: 0.5696\n",
      "14/14 [==============================] - 1s 94ms/step - loss: 1.5832 - accuracy: 0.4380\n",
      ">#6: 43.800\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 15s 459ms/step - loss: 1.4604 - accuracy: 0.3234\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 15s 456ms/step - loss: 1.2441 - accuracy: 0.4377\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 14s 453ms/step - loss: 1.1436 - accuracy: 0.4817\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 14s 451ms/step - loss: 1.1435 - accuracy: 0.4978\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 14s 448ms/step - loss: 1.1100 - accuracy: 0.5330\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 14s 447ms/step - loss: 1.2761 - accuracy: 0.4533\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 16s 515ms/step - loss: 1.1123 - accuracy: 0.5007\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 14s 441ms/step - loss: 1.0592 - accuracy: 0.5447\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 14s 438ms/step - loss: 1.0728 - accuracy: 0.5369\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 14s 442ms/step - loss: 0.9961 - accuracy: 0.5667\n",
      "14/14 [==============================] - 1s 83ms/step - loss: 1.5756 - accuracy: 0.4266\n",
      ">#7: 42.662\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 14s 450ms/step - loss: 1.4692 - accuracy: 0.3249\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 15s 455ms/step - loss: 1.2869 - accuracy: 0.4240\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 14s 442ms/step - loss: 1.2508 - accuracy: 0.4304\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 14s 443ms/step - loss: 1.1920 - accuracy: 0.4885\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 14s 444ms/step - loss: 1.1006 - accuracy: 0.5105\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 14s 446ms/step - loss: 1.0497 - accuracy: 0.5232\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 14s 450ms/step - loss: 1.0359 - accuracy: 0.5540\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 14s 453ms/step - loss: 1.0994 - accuracy: 0.5398\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 14s 450ms/step - loss: 1.1995 - accuracy: 0.5012\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 17s 516ms/step - loss: 1.0773 - accuracy: 0.5393\n",
      "14/14 [==============================] - 1s 87ms/step - loss: 1.5721 - accuracy: 0.4653\n",
      ">#8: 46.530\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 14s 423ms/step - loss: 1.4642 - accuracy: 0.3298\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 14s 426ms/step - loss: 1.2900 - accuracy: 0.4333\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 13s 420ms/step - loss: 1.1850 - accuracy: 0.4856\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 14s 426ms/step - loss: 1.1918 - accuracy: 0.4665\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 14s 425ms/step - loss: 1.1127 - accuracy: 0.5076\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 14s 426ms/step - loss: 1.0975 - accuracy: 0.5198\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 14s 427ms/step - loss: 1.0414 - accuracy: 0.5579\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 14s 424ms/step - loss: 1.0335 - accuracy: 0.5657\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 13s 422ms/step - loss: 0.9631 - accuracy: 0.5887\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 14s 428ms/step - loss: 0.9023 - accuracy: 0.6229\n",
      "14/14 [==============================] - 1s 83ms/step - loss: 1.5676 - accuracy: 0.4278\n",
      ">#9: 42.776\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 14s 435ms/step - loss: 1.4680 - accuracy: 0.3356\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 14s 436ms/step - loss: 1.2735 - accuracy: 0.4343\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 14s 437ms/step - loss: 1.2644 - accuracy: 0.4450\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 16s 497ms/step - loss: 1.1773 - accuracy: 0.4851\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 14s 434ms/step - loss: 1.0965 - accuracy: 0.5002\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 14s 438ms/step - loss: 1.0677 - accuracy: 0.5213\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 16s 485ms/step - loss: 1.0245 - accuracy: 0.5545\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 14s 438ms/step - loss: 1.0203 - accuracy: 0.5784\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 14s 440ms/step - loss: 1.0067 - accuracy: 0.5696\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 14s 441ms/step - loss: 1.0406 - accuracy: 0.5286\n",
      "14/14 [==============================] - 1s 88ms/step - loss: 1.5472 - accuracy: 0.4937\n",
      ">#10: 49.374\n",
      "[41.18316173553467, 40.95562994480133, 41.75198972225189, 48.236632347106934, 30.830490589141846, 43.79977285861969, 42.66211688518524, 46.53014838695526, 42.77588129043579, 49.37428832054138]\n",
      "Accuracy: 42.810% (+/-4.879)\n"
     ]
    }
   ],
   "source": [
    "run_experiment(repeats=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
